{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4783294,"sourceType":"datasetVersion","datasetId":2768804}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fvcore","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport pickle\nimport logging\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\nimport numpy as np\nfrom torchvision.transforms.functional import to_pil_image\nimport time\nimport psutil  # For CPU memory usage tracking\nimport torchvision.transforms as transforms\nfrom datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T07:06:21.064279Z","iopub.execute_input":"2025-03-01T07:06:21.064542Z","iopub.status.idle":"2025-03-01T07:06:27.362336Z","shell.execute_reply.started":"2025-03-01T07:06:21.064523Z","shell.execute_reply":"2025-03-01T07:06:27.361684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass Logger:\n    @staticmethod\n    def setup_logging(method_name):\n        log_dir = f\"/kaggle/working/logs/{method_name}\"\n        os.makedirs(log_dir, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        log_file = f\"{log_dir}/{method_name}_{timestamp}.log\"\n        \n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - %(levelname)s - %(message)s',\n            handlers=[\n                logging.FileHandler(log_file),\n                logging.StreamHandler()\n            ]\n        )\n        return log_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T07:06:27.363600Z","iopub.execute_input":"2025-03-01T07:06:27.364221Z","iopub.status.idle":"2025-03-01T07:06:27.368408Z","shell.execute_reply.started":"2025-03-01T07:06:27.364188Z","shell.execute_reply":"2025-03-01T07:06:27.367792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_pretrained_model(model_name='i3d_r50', num_classes=10):\n    model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    model.blocks[-1].proj = nn.Linear(model.blocks[-1].proj.in_features, num_classes)\n    for param in model.blocks[-1].proj.parameters():\n        param.requires_grad = True\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T07:06:27.369342Z","iopub.execute_input":"2025-03-01T07:06:27.369706Z","iopub.status.idle":"2025-03-01T07:06:27.387829Z","shell.execute_reply.started":"2025-03-01T07:06:27.369677Z","shell.execute_reply":"2025-03-01T07:06:27.387090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class VideoDataset(data.Dataset):\n    def __init__(self, data, labels, transform=None):\n        \"\"\"\n        Args:\n            data (numpy array): Shape (N, T, H, W, C) - (samples, frames, height, width, channels)\n            labels (numpy array): Corresponding labels\n            transform (torchvision.transforms.Compose): Transformations for resizing & normalization\n        \"\"\"\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n        # Define default transform if none is provided\n        if self.transform is None:\n            self.transform = transforms.Compose([\n                transforms.Resize((224, 224)),  # Resize PIL Image\n                transforms.ToTensor(),  # Convert back to Tensor\n                transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize\n            ])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Load a single video sample and process all frames.\n        \"\"\"\n        video = torch.tensor(self.data[idx], dtype=torch.float32).permute(3, 0, 1, 2)  # (T, H, W, C) -> (C, T, H, W)\n\n        # Convert each frame to PIL, apply transformations, and stack back\n        resized_frames = []\n        for frame in video.permute(1, 0, 2, 3):  # Convert (C, T, H, W) -> (T, C, H, W)\n            pil_frame = to_pil_image(frame)  # Convert tensor to PIL Image\n            resized_frame = self.transform(pil_frame)  # Resize and transform\n            resized_frames.append(resized_frame)\n\n        # Stack frames back into a tensor (C, T, H, W)\n        video = torch.stack(resized_frames, dim=1)\n\n        label = torch.tensor(self.labels[idx], dtype=torch.long)  # Ensure label is a tensor\n        return video, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T07:06:27.388531Z","iopub.execute_input":"2025-03-01T07:06:27.388766Z","iopub.status.idle":"2025-03-01T07:06:27.433328Z","shell.execute_reply.started":"2025-03-01T07:06:27.388747Z","shell.execute_reply":"2025-03-01T07:06:27.432051Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ModelLoader:\n    @staticmethod\n    def load_pretrained_model(model_name='i3d_r50', num_classes=10):\n        model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)\n        for param in model.parameters():\n            param.requires_grad = False\n        \n        model.blocks[-1].proj = nn.Linear(model.blocks[-1].proj.in_features, num_classes)\n        for param in model.blocks[-1].proj.parameters():\n            param.requires_grad = True\n        \n        return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T07:06:27.433765Z","iopub.status.idle":"2025-03-01T07:06:27.434038Z","shell.execute_reply":"2025-03-01T07:06:27.433930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = ModelLoader.load_pretrained_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T07:06:27.434794Z","iopub.status.idle":"2025-03-01T07:06:27.435135Z","shell.execute_reply":"2025-03-01T07:06:27.434983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_loader, valid_loader, test_loader, device, method_name, fold, num_epochs=10, lr=0.001, writer=None):\n        self.model = model.to(device)\n        self.device = device\n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', patience=3, factor=0.5)\n        self.train_loader = train_loader\n        self.valid_loader = valid_loader\n        self.test_loader = test_loader\n        self.num_epochs = num_epochs\n        self.writer = writer\n        self.method_name = method_name\n        self.fold = fold\n        self.best_val_acc = 0.0\n\n    def train(self):\n        start_time = time.time()  # Start timing\n        process = psutil.Process()  # Get current process info\n        max_memory_cpu = 0\n        max_memory_gpu = 0\n\n        for epoch in range(self.num_epochs):\n            self.model.train()\n            running_loss, correct, total = 0.0, 0, 0\n\n            for inputs, labels in self.train_loader:\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\n                \n                self.optimizer.zero_grad()\n                outputs = self.model(inputs)\n                loss = self.criterion(outputs, labels)\n                loss.backward()\n                self.optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                _, preds = torch.max(outputs, 1)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n                \n                # Track max memory usage\n                max_memory_cpu = max(max_memory_cpu, process.memory_info().rss / (1024 * 1024))\n                if torch.cuda.is_available():\n                    max_memory_gpu = max(max_memory_gpu, torch.cuda.max_memory_allocated(self.device) / (1024 * 1024))\n\n            train_loss = running_loss / total\n            train_acc = correct / total\n\n            val_acc, val_loss = self.evaluate(self.valid_loader, calculate_loss=True)\n            self.scheduler.step(val_loss)\n\n            epoch_time = time.time() - start_time\n            logging.info(f\"{self.method_name} - Fold {self.fold+1} - Epoch {epoch+1}/{self.num_epochs} - \"\n                         f\"Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, \"\n                         f\"Time: {epoch_time:.2f}s, CPU Mem: {max_memory_cpu:.2f}MB, GPU Mem: {max_memory_gpu:.2f}MB\")\n\n            if self.writer:\n                self.writer.add_scalar(f'{self.method_name}/Loss/train/fold_{self.fold+1}', train_loss, epoch)\n                self.writer.add_scalar(f'{self.method_name}/Loss/valid/fold_{self.fold+1}', val_loss, epoch)\n                self.writer.add_scalar(f'{self.method_name}/Accuracy/train/fold_{self.fold+1}', train_acc, epoch)\n                self.writer.add_scalar(f'{self.method_name}/Accuracy/valid/fold_{self.fold+1}', val_acc, epoch)\n                self.writer.add_scalar(f'{self.method_name}/Memory/CPU/fold_{self.fold+1}', max_memory_cpu, epoch)\n                if torch.cuda.is_available():\n                    self.writer.add_scalar(f'{self.method_name}/Memory/GPU/fold_{self.fold+1}', max_memory_gpu, epoch)\n\n    def evaluate(self, loader, calculate_loss=False):\n        self.model.eval()\n        correct, total, total_loss = 0, 0, 0.0\n        all_preds, all_labels = [], []\n\n        with torch.no_grad():\n            for inputs, labels in loader:\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\n                outputs = self.model(inputs)\n                _, preds = torch.max(outputs, 1)\n                \n                all_preds.append(preds)\n                all_labels.append(labels)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n\n                if calculate_loss:\n                    total_loss += self.criterion(outputs, labels).item() * inputs.size(0)\n        \n        accuracy = correct / total\n        \n        if calculate_loss:\n            return accuracy, total_loss / total\n        \n        all_preds = torch.cat(all_preds).cpu().numpy()\n        all_labels = torch.cat(all_labels).cpu().numpy()\n        precision = precision_score(all_labels, all_preds, average='weighted')\n        recall = recall_score(all_labels, all_preds, average='weighted')\n        f1 = f1_score(all_labels, all_preds, average='weighted')\n        conf_matrix = confusion_matrix(all_labels, all_preds)\n\n        logging.info(f\"{self.method_name} - Evaluation - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, \"\n                     f\"Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n        logging.info(f\"{self.method_name} - Confusion Matrix:\\n{conf_matrix}\")\n        return accuracy, precision, recall, f1, conf_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T07:06:21.038932Z","iopub.execute_input":"2025-03-01T07:06:21.039211Z","iopub.status.idle":"2025-03-01T07:06:21.062459Z","shell.execute_reply.started":"2025-03-01T07:06:21.039184Z","shell.execute_reply":"2025-03-01T07:06:21.061606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TrainingPipeline:\n    def __init__(self, method, num_epochs=50, batch_size=8, lr=0.001):\n        self.method = method\n        self.num_epochs = num_epochs\n        self.batch_size = batch_size\n        self.lr = lr\n        self.log_dir = self.setup_logging()\n        self.writer = SummaryWriter(log_dir=f\"/kaggle/working/tensorboard_logs/{method}\")\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        logging.info(f\"Using device: {self.device}\")\n        self.method_paths = {\n            \"combined\": {\"data\": \"/kaggle/input/threedpickles/classroom/classroom/data.pkl\", \"labels\": \"/kaggle/input/threedpickles/classroom/classroom/labels.pkl\"},\n            \"student\": {\"data\": \"/kaggle/input/threedpickles/student/student/data.pkl\", \"labels\": \"/kaggle/input/threedpickles/student/student/labels.pkl\"},\n            \"teacher\": {\"data\": \"/kaggle/input/threedpickles/teacher/teacher/data.pkl\", \"labels\": \"/kaggle/input/threedpickles/teacher/teacher/labels.pkl\"}\n        }\n        self.data, self.labels = self.load_data()\n        self.num_classes = len(set(self.labels))\n    \n    def setup_logging(self):\n        log_dir = f\"/kaggle/workgin/logs/{self.method}\"\n        os.makedirs(log_dir, exist_ok=True)\n        return log_dir\n    \n    def load_data(self):\n        logging.info(f\"Loading {self.method} data...\")\n        with open(self.method_paths[self.method][\"data\"], 'rb') as f:\n            data = pickle.load(f)\n        with open(self.method_paths[self.method][\"labels\"], 'rb') as f:\n            labels = pickle.load(f)\n        logging.info(f\"{self.method} dataset: {len(data)} samples, {len(set(labels))} classes\")\n        return data, labels\n    def run(self):\n        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n        fold_results = []\n    \n        for fold, (train_idx, val_idx) in enumerate(skf.split(self.data, self.labels)):\n            start_time = time.time()\n            process = psutil.Process()\n            torch.cuda.reset_max_memory_allocated()\n    \n            logging.info(f\"Starting {self.method} - Fold {fold+1}/5\")\n            print(f\"Starting {self.method} - Fold {fold+1}/5\")\n    \n            x_train = [self.data[i] for i in train_idx]\n            y_train = [self.labels[i] for i in train_idx]\n            x_valid = [self.data[i] for i in val_idx]\n            y_valid = [self.labels[i] for i in val_idx]\n            x_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size=0.5, random_state=42)\n    \n            train_dataset = VideoDataset(x_train, y_train)\n            valid_dataset = VideoDataset(x_valid, y_valid)\n            test_dataset = VideoDataset(x_test, y_test)\n    \n            train_loader = data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n            valid_loader = data.DataLoader(valid_dataset, batch_size=self.batch_size, shuffle=False)\n            test_loader = data.DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n    \n            model = ModelLoader.load_pretrained_model(num_classes=self.num_classes)\n    \n            trainer = Trainer(\n                model=model,\n                train_loader=train_loader,\n                valid_loader=valid_loader,\n                test_loader=test_loader,\n                device=self.device,\n                method_name=self.method,\n                fold=fold,\n                num_epochs=self.num_epochs,\n                lr=self.lr,\n                writer=self.writer\n            )\n    \n            trainer.train()\n            test_accuracy, test_precision, test_recall, test_f1, conf_matrix = trainer.evaluate(test_loader)\n    \n            end_time = time.time()\n            time_taken = end_time - start_time\n            max_memory_cpu = process.memory_info().rss / (1024 ** 2)  # Convert bytes to MB\n            max_memory_gpu = torch.cuda.max_memory_allocated() / (1024 ** 2) if torch.cuda.is_available() else 0\n    \n            logging.info(f\"Fold {fold+1} Time Taken: {time_taken:.2f} seconds\")\n            logging.info(f\"Fold {fold+1} Peak CPU Memory Usage: {max_memory_cpu:.2f} MB\")\n            logging.info(f\"Fold {fold+1} Peak GPU Memory Usage: {max_memory_gpu:.2f} MB\")\n    \n            self.writer.add_scalar(f'{self.method}/Time/fold_{fold+1}', time_taken, fold)\n            self.writer.add_scalar(f'{self.method}/Memory/CPU/fold_{fold+1}', max_memory_cpu, fold)\n            self.writer.add_scalar(f'{self.method}/Memory/GPU/fold_{fold+1}', max_memory_gpu, fold)\n    \n            model_dir = f\"/kaggle/working/model_weights/{self.method}\"\n            os.makedirs(model_dir, exist_ok=True)\n            torch.save(model.state_dict(), f\"{model_dir}/fold_{fold+1}_final.pth\")\n    \n            fold_results.append({\n                'fold': fold + 1,\n                'accuracy': test_accuracy,\n                'precision': test_precision,\n                'recall': test_recall,\n                'f1': test_f1,\n                'time': time_taken,\n                'cpu_memory': max_memory_cpu,\n                'gpu_memory': max_memory_gpu\n            })\n    \n        avg_accuracy = np.mean([res['accuracy'] for res in fold_results])\n        avg_precision = np.mean([res['precision'] for res in fold_results])\n        avg_recall = np.mean([res['recall'] for res in fold_results])\n        avg_f1 = np.mean([res['f1'] for res in fold_results])\n        avg_time = np.mean([res['time'] for res in fold_results])\n        avg_cpu_memory = np.mean([res['cpu_memory'] for res in fold_results])\n        avg_gpu_memory = np.mean([res['gpu_memory'] for res in fold_results])\n    \n        logging.info(f\"{self.method} - Average results across folds:\")\n        logging.info(f\"Accuracy: {avg_accuracy:.4f}\")\n        logging.info(f\"Precision: {avg_precision:.4f}\")\n        logging.info(f\"Recall: {avg_recall:.4f}\")\n        logging.info(f\"F1-score: {avg_f1:.4f}\")\n        logging.info(f\"Avg Time Taken: {avg_time:.2f} seconds\")\n        logging.info(f\"Avg Peak CPU Memory: {avg_cpu_memory:.2f} MB\")\n        logging.info(f\"Avg Peak GPU Memory: {avg_gpu_memory:.2f} MB\")\n    \n        self.writer.add_hparams(\n            {'method': self.method, 'epochs': self.num_epochs, 'batch_size': self.batch_size, 'lr': self.lr},\n            {\n                'hparam/accuracy': avg_accuracy,\n                'hparam/precision': avg_precision,\n                'hparam/recall': avg_recall,\n                'hparam/f1': avg_f1,\n                'hparam/time': avg_time,\n                'hparam/cpu_memory': avg_cpu_memory,\n                'hparam/gpu_memory': avg_gpu_memory\n            }\n        )\n    \n        self.writer.close()\n        return fold_results\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    os.makedirs(\"/kaggle/working/logs\", exist_ok=True)\n    os.makedirs(\"/kaggle/working/model_weights\", exist_ok=True)\n    os.makedirs(\"/kaggle/working/tensorboard_logs\", exist_ok=True)\n    \n    params = {'num_epochs': 100, 'batch_size': 32, 'lr': 0.001}\n    methods = [\"combined\", \"student\", \"teacher\"]\n    results = {}\n    \n    for method in methods:\n        logging.info(f\"==== Starting training for {method} dataset ====\")\n        pipeline = TrainingPipeline(method=method, **params)\n        results[method] = pipeline.run()\n        logging.info(f\"==== Completed training for {method} dataset ====\")\n    \n    logging.info(\"==== Summary of Results ====\")\n    for method in methods:\n        avg_accuracy = np.mean([res['accuracy'] for res in results[method]])\n        logging.info(f\"{method}: Average Accuracy = {avg_accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"main()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-01T07:06:17.083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}