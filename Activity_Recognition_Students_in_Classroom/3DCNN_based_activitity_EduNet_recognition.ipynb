{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4783294,"sourceType":"datasetVersion","datasetId":2768804}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install keras_preprocessing\n# !pip install scikeras\n# !pip install scikit-elm\n# !pip install scikit-learn\n# !python -m pip install --upgrade pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T12:36:12.679783Z","iopub.execute_input":"2025-02-22T12:36:12.680063Z","iopub.status.idle":"2025-02-22T12:36:12.683911Z","shell.execute_reply.started":"2025-02-22T12:36:12.680033Z","shell.execute_reply":"2025-02-22T12:36:12.683039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Logging ---\nimport logging\n\n# --- Operating System and File Handling ---\nimport os\nimport glob\nimport pickle\n\n# --- Data Handling ---\nimport pandas as pd\nimport numpy as np\n\n# --- Image Processing ---\nimport cv2\nfrom skimage import io\n\n# --- TensorFlow and Keras ---\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import (\n    Dense, Activation, Flatten, Dropout, BatchNormalization,\n    GlobalAveragePooling2D, Conv2D, MaxPooling2D,\n    GlobalAveragePooling3D, Conv3D, MaxPooling3D\n)\nfrom tensorflow.keras import regularizers, optimizers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom keras import backend as K\n\n# --- Scikit-learn ---\nfrom sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# --- Other Utilities ---\nimport matplotlib.pyplot as plt\nimport warnings\nimport tqdm\nimport time\nimport psutil\n\n# --- Suppress Warnings ---\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T12:09:07.103965Z","iopub.execute_input":"2025-02-22T12:09:07.104353Z","iopub.status.idle":"2025-02-22T12:09:07.110752Z","shell.execute_reply.started":"2025-02-22T12:09:07.104327Z","shell.execute_reply":"2025-02-22T12:09:07.109705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.seed(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T12:07:17.771184Z","iopub.execute_input":"2025-02-22T12:07:17.771758Z","iopub.status.idle":"2025-02-22T12:07:17.775223Z","shell.execute_reply.started":"2025-02-22T12:07:17.771718Z","shell.execute_reply":"2025-02-22T12:07:17.774343Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Config","metadata":{}},{"cell_type":"code","source":"class config:\n    IMG_SIZE = 128\n    BATCH_SIZE = 32\n    EPOCHS = 100\n    N_SPLITS = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T12:07:17.777075Z","iopub.execute_input":"2025-02-22T12:07:17.777340Z","iopub.status.idle":"2025-02-22T12:07:17.914277Z","shell.execute_reply.started":"2025-02-22T12:07:17.777318Z","shell.execute_reply":"2025-02-22T12:07:17.913283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass Conv3DCNNTrainer:\n    def __init__(self, data_path, labels_path, methods, epochs=50, batch_size=8, n_splits=5):\n        self.data_path = data_path\n        self.labels_path = labels_path\n        self.methods = methods\n        self.epochs = epochs\n        self.batch_size = batch_size\n        self.n_splits = n_splits\n        self.data, self.labels = self.load_data()\n        \n    def setup_logging(self, method):\n        log_file = f\"/kaggle/working/{method}_training_log.log\"\n        \n        # Ensure the directory exists\n        os.makedirs(os.path.dirname(log_file), exist_ok=True)\n        \n        # Create a new logger instance\n        logger = logging.getLogger(method)\n        logger.setLevel(logging.INFO)\n        \n        # Avoid duplicate handlers\n        if not logger.hasHandlers():\n            # File handler (logs to file)\n            file_handler = logging.FileHandler(log_file)\n            file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n            \n            # Stream handler (prints to console)\n            stream_handler = logging.StreamHandler()\n            stream_handler.setFormatter(logging.Formatter('%(message)s'))  # Cleaner console output\n            \n            # Add handlers to logger\n            logger.addHandler(file_handler)\n            logger.addHandler(stream_handler)\n        \n        return logger\n\n\n    def load_data(self):\n        with open(self.data_path, \"rb\") as f:\n            data = pickle.load(f)\n        with open(self.labels_path, \"rb\") as f:\n            labels = pickle.load(f)\n        return data, labels\n\n    def define_classes(self, method):\n        class_map = {\n            \"combined\": ['Arguing','Eating_in_classroom','Explaining_the_Subject','HandRaise', 'Holding_Book','Holding_Mobile_Phone','Reading_Book','Sitting_on_Desk', 'Writing_On_Board','Writting_on_Textbook'],\n            \"student\": ['Arguing','Eating_in_classroom','HandRaise','Reading_Book', 'Sitting_on_Desk','Writting_on_Textbook'],\n            \"teacher\": ['Explaining_the_Subject','Holding_Book','Holding_Mobile_Phone','Writing_On_Board']\n        }\n        return class_map.get(method, [])\n\n    def build_model(self, input_shape, num_classes):\n        model = Sequential([\n            Conv3D(64, kernel_size=3, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n            MaxPooling3D(pool_size=2),\n            BatchNormalization(),\n            \n            Conv3D(64, kernel_size=3, activation=\"relu\", padding=\"same\"),\n            MaxPooling3D(pool_size=2),\n            BatchNormalization(),\n            \n            Conv3D(128, kernel_size=3, activation=\"relu\", padding=\"same\"),\n            MaxPooling3D(pool_size=2),\n            BatchNormalization(),\n            \n            GlobalAveragePooling3D(),\n            Dense(512, activation=\"relu\"),\n            Dropout(0.3),\n            Dense(num_classes, activation=\"softmax\")\n        ])\n        \n        lr_schedule = ExponentialDecay(\n            initial_learning_rate=0.0001, decay_steps=100000, decay_rate=0.96, staircase=True\n        )\n        \n        model.compile(\n            loss=\"categorical_crossentropy\",\n            optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n            metrics=[\"accuracy\"]\n        )\n        return model\n\n    def train_with_kfold(self, method):\n        classes = self.define_classes(method)\n\n        log_file = self.setup_logging(method)\n        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n        fold_no = 1\n        all_fold_times, all_metrics = [], []\n        input_shape = (self.data.shape[1], 128, 128, 3)\n        tensorboard_dir = f\"/kaggle/working/tensorboard_logs/{method}\"\n        model_dir = f\"/kaggle/working/saved_models/{method}\"\n        os.makedirs(tensorboard_dir, exist_ok=True)\n        os.makedirs(model_dir, exist_ok=True)\n\n        for train_idx, val_idx in skf.split(self.data, self.labels):\n            start_time = time.time()\n            start_memory = psutil.Process().memory_info().rss / (1024 * 1024)            \n\n            x_train_df = self.data[train_idx]\n            x_valid_df = self.data[val_idx]\n            y_train_labels = self.labels[train_idx]\n            y_valid_labels = self.labels[val_idx]\n\n            \n            x_valid, x_test, y_valid, y_test = train_test_split(x_valid_df, y_valid_labels, test_size=0.5, random_state=42)\n\n\n            y_train = tf.keras.utils.to_categorical(y_train_labels, num_classes=len(classes))\n            y_valid = tf.keras.utils.to_categorical(y_valid, num_classes=len(classes))\n            y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(classes))\n\n            model = self.build_model(input_shape, len(classes))\n            tensorboard_callback = TensorBoard(log_dir=f'{tensorboard_dir}/fold_{fold_no}')\n\n            history = model.fit(\n                x_train_df, y_train,\n                validation_data=(x_valid, y_valid),\n                epochs=self.epochs,\n                batch_size=self.batch_size,\n                callbacks=[tensorboard_callback],\n                verbose=0\n            )\n            \n            model.save(f\"{model_dir}/fold_{fold_no}.h5\")\n\n            y_pred_test = np.argmax(model.predict(x_test), axis=1)\n            y_true_test = np.argmax(y_test, axis=1)\n\n            test_acc = accuracy_score(y_true_test, y_pred_test)\n            test_precision = precision_score(y_true_test, y_pred_test, average='weighted')\n            test_recall = recall_score(y_true_test, y_pred_test, average='weighted')\n            test_f1 = f1_score(y_true_test, y_pred_test, average='weighted')\n            test_conf_matrix = confusion_matrix(y_true_test, y_pred_test)\n\n            train_acc = history.history['accuracy'][-1]\n            val_acc = history.history['val_accuracy'][-1]\n            \n            fold_time = time.time() - start_time\n            memory_usage = (psutil.Process().memory_info().rss / (1024 * 1024)) - start_memory\n            \n            logging.info(f\"Fold {fold_no}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}\")\n            logging.info(f\"Test Metrics - Acc: {test_acc:.4f}, Prec: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n            logging.info(f\"Time: {fold_time:.2f}s, Memory: {memory_usage:.2f}MB\")\n            logging.info(f\"Confusion Matrix (Test Set):\\n{test_conf_matrix}\")\n        \n            print(f\"Fold {fold_no}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}\")\n            print(f\"Test Metrics - Acc: {test_acc:.4f}, Prec: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n            print(f\"Time: {fold_time:.2f}s, Memory: {memory_usage:.2f}MB\")\n            print(f\"Confusion Matrix (Test Set):\\n{test_conf_matrix}\")\n\n            all_fold_times.append(fold_time)\n            all_metrics.append((test_acc, test_precision, test_recall, test_f1))\n            fold_no += 1\n        \n        avg_metrics = np.mean(all_metrics, axis=0)\n        logging.info(f\"Overall - Accuracy: {avg_metrics[0]:.4f}, Precision: {avg_metrics[1]:.4f}, Recall: {avg_metrics[2]:.4f}, F1 Score: {avg_metrics[3]:.4f}\")\n        logging.info(f\"Total Time: {sum(all_fold_times):.2f}s, Avg Time per Fold: {np.mean(all_fold_times):.2f}s\")\n\n        print(f\"Overall - Accuracy: {avg_metrics[0]:.4f}, Precision: {avg_metrics[1]:.4f}, Recall: {avg_metrics[2]:.4f}, F1 Score: {avg_metrics[3]:.4f}\")\n        print(f\"Total Time: {sum(all_fold_times):.2f}s, Avg Time per Fold: {np.mean(all_fold_times):.2f}s\")\n            \n    \n    def run(self):\n        for method in self.methods:\n            self.train_with_kfold(method)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T12:44:28.945342Z","iopub.execute_input":"2025-02-22T12:44:28.945697Z","iopub.status.idle":"2025-02-22T12:44:28.967133Z","shell.execute_reply.started":"2025-02-22T12:44:28.945669Z","shell.execute_reply":"2025-02-22T12:44:28.966114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"method_paths = {\n    \"combined\": {\n        \"data_path\": \"/kaggle/input/threedpickles/classroom/classroom/data.pkl\",\n        \"labels_path\": \"/kaggle/input/threedpickles/classroom/classroom/labels.pkl\"\n    },\n    \"student\": {\n        \"data_path\": \"/kaggle/input/threedpickles/student/student/data.pkl\",\n        \"labels_path\": \"/kaggle/input/threedpickles/student/student/labels.pkl\"\n    },\n    \"teacher\": {\n        \"data_path\": \"/kaggle/input/threedpickles/teacher/teacher/data.pkl\",\n        \"labels_path\": \"/kaggle/input/threedpickles/teacher/teacher/labels.pkl\"\n    }\n}\n\n\nfor method in [\"combined\", \"student\", \"teacher\"]:\n    trainer = Conv3DCNNTrainer(\n        data_path=method_paths[method][\"data_path\"],\n        labels_path=method_paths[method][\"labels_path\"],\n        methods=[method],\n        epochs=config.EPOCHS,\n        batch_size=config.BATCH_SIZE,\n        n_splits=config.N_SPLITS\n    )\n\n    print(f\"Running training for method: {method}\")\n    trainer.run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T12:11:08.923695Z","iopub.execute_input":"2025-02-22T12:11:08.924052Z","execution_failed":"2025-02-22T12:12:17.067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}