{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 19:18:22.935014: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-15 19:18:22.936500: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-15 19:18:22.970630: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-15 19:18:22.971051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-15 19:18:23.600711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import extract_text_and_labels, tokenizer, get_sequences\n",
    "from model import model_0\n",
    "from utils import import_data, show_confusion_matrix, show_history, get_index\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp \n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import ProgbarLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = './dataset/training.csv'\n",
    "valid_path = './dataset/validation.csv'\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "valid = pd.read_csv(valid_path)\n",
    "\n",
    "train_text, train_labels = extract_text_and_labels(train)\n",
    "valid_text, valid_labels = extract_text_and_labels(valid)\n",
    "\n",
    "tokenizer_train, train_tok = tokenizer(train_text)\n",
    "tokenizer_valid, valid_tok = tokenizer(valid_text)\n",
    "\n",
    "max_len = 50 # max sequence length\n",
    "\n",
    "padded_train_seq = get_sequences(tokenizer_train, train_tok, max_len)\n",
    "padded_valid_seq = get_sequences(tokenizer_valid, valid_tok, max_len)\n",
    "\n",
    "class_to_index, index_to_class = get_index()\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "valid_labels = np.array(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model_0()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='weights.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='max',\n",
    "    verbose=1 # Display messages when saving weights\n",
    ")\n",
    "\n",
    "hypothesis = model.fit(\n",
    "    x=padded_train_seq,\n",
    "    y=train_labels,\n",
    "    validation_data=(padded_valid_seq, valid_labels),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_accuracy', patience=2),\n",
    "        checkpoint_callback\n",
    "    ],\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "model.save('Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 764ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import messagebox\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('./model/Model.h5')\n",
    "\n",
    "# Create a function to preprocess text input and make predictions\n",
    "def predict_emotion():\n",
    "    user_input = text_entry.get()  # Get text input from the user\n",
    "    if user_input:\n",
    "        # Tokenize and preprocess the input text\n",
    "        user_seq = tokenizer_train.texts_to_sequences([user_input])\n",
    "        padded_user_seq = pad_sequences(user_seq, truncating='post', padding='post', maxlen=max_len)\n",
    "        \n",
    "        # Make a prediction using the loaded model\n",
    "        prediction = model.predict(padded_user_seq)\n",
    "        \n",
    "        # Get the emotion label with the highest probability\n",
    "        predicted_label = index_to_class[np.argmax(prediction)]\n",
    "        \n",
    "        # Display the result in a message box\n",
    "        result_message = f\"Predicted Emotion: {predicted_label}\"\n",
    "        messagebox.showinfo(\"Emotion Prediction Result\", result_message)\n",
    "    else:\n",
    "        messagebox.showwarning(\"Empty Input\", \"Please enter text for prediction.\")\n",
    "\n",
    "# Create the main GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "\n",
    "# Create a label and text entry field\n",
    "label = ttk.Label(root, text=\"Enter Text:\")\n",
    "label.pack(pady=10)\n",
    "text_entry = ttk.Entry(root, width=40)\n",
    "text_entry.pack(pady=5)\n",
    "\n",
    "# Create a button to make predictions\n",
    "predict_button = ttk.Button(root, text=\"Predict Emotion\", command=predict_emotion)\n",
    "predict_button.pack(pady=10)\n",
    "\n",
    "# Start the GUI application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
